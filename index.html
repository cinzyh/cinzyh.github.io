<!DOCTYPE html>



  


<html class="theme-next muse use-motion" lang="zh-Hans">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/cinzyh.github.io/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/cinzyh.github.io/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/cinzyh.github.io/css/main.css?v=5.1.4" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/cinzyh.github.io/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/cinzyh.github.io/images/-lion-2.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/cinzyh.github.io/images/-lion.png?v=5.1.4">


  <link rel="mask-icon" href="/cinzyh.github.io/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="Hexo, NexT" />










<meta property="og:type" content="website">
<meta property="og:title" content="cinzyh_Blog">
<meta property="og:url" content="https://cinzyh.github.io/index.html">
<meta property="og:site_name" content="cinzyh_Blog">
<meta property="article:author" content="cinzyh">
<meta name="twitter:card" content="summary">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/cinzyh.github.io/',
    scheme: 'Muse',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="https://cinzyh.github.io/"/>





  <title>cinzyh_Blog</title>
  








<meta name="generator" content="Hexo 4.2.0"></head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <div class="container sidebar-position-left 
  page-home">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/cinzyh.github.io/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">cinzyh_Blog</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/cinzyh.github.io/%20" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/cinzyh.github.io/archives/%20" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            归档
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://cinzyh.github.io/cinzyh.github.io/2020/02/13/%E5%8A%A8%E6%89%8B%E5%AD%A6%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="cinzyh">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/cinzyh.github.io/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="cinzyh_Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/cinzyh.github.io/2020/02/13/%E5%8A%A8%E6%89%8B%E5%AD%A6%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/" itemprop="url">动手学深度学习笔记</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2020-02-13T21:11:53+08:00">
                2020-02-13
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="线性回归"><a href="#线性回归" class="headerlink" title="线性回归"></a>线性回归</h1><h1 id="softmax与分类模型"><a href="#softmax与分类模型" class="headerlink" title="softmax与分类模型"></a>softmax与分类模型</h1><h1 id="多层感知机"><a href="#多层感知机" class="headerlink" title="多层感知机"></a>多层感知机</h1><h3 id="隐藏层"><a href="#隐藏层" class="headerlink" title="隐藏层"></a>隐藏层</h3><p>下图展示了一个多层感知机的神经网络图，它含有一个隐藏层，该层中有5个隐藏单元。</p>
<p><img src="https://cdn.kesci.com/upload/image/q5ho684jmh.png" alt="Image Name"></p>
<h3 id="表达公式"><a href="#表达公式" class="headerlink" title="表达公式"></a>表达公式</h3><script type="math/tex; mode=display">
\begin{aligned} \boldsymbol{H} &= \boldsymbol{X} \boldsymbol{W}_h + \boldsymbol{b}_h,\\ \boldsymbol{O} &= \boldsymbol{H} \boldsymbol{W}_o + \boldsymbol{b}_o, \end{aligned}</script><p>也就是将隐藏层的输出直接作为输出层的输入。如果将以上两个式子联立起来，可以得到</p>
<script type="math/tex; mode=display">
\boldsymbol{O} = (\boldsymbol{X} \boldsymbol{W}_h + \boldsymbol{b}_h)\boldsymbol{W}_o + \boldsymbol{b}_o = \boldsymbol{X} \boldsymbol{W}_h\boldsymbol{W}_o + \boldsymbol{b}_h \boldsymbol{W}_o + \boldsymbol{b}_o.</script><p>仍然等价于一个单层的神经网络。</p>
<h3 id="激活函数"><a href="#激活函数" class="headerlink" title="激活函数"></a>激活函数</h3><h4 id="ReLU函数"><a href="#ReLU函数" class="headerlink" title="ReLU函数"></a>ReLU函数</h4><p>ReLU（rectified linear unit）函数提供了一个很简单的<em>非线性变换</em>。给定元素，该函数定义为</p>
<script type="math/tex; mode=display">
\text{ReLU}(x) = \max(x, 0).</script><p>可以看出，ReLU函数<u>只保留正数元素，并将负数元素清零</u>。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">%matplotlib inline</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line">sys.path.append(<span class="string">"/home/kesci/input"</span>)®</span><br><span class="line"><span class="keyword">import</span> d2lzh1981 <span class="keyword">as</span> d2l</span><br><span class="line">print(torch.__version__)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">xyplot</span><span class="params">(x_vals, y_vals, name)</span>:</span> <span class="comment">#绘制激活函数的图像，参数为横纵坐标值和函数的名称name</span></span><br><span class="line">    <span class="comment"># d2l.set_figsize(figsize=(5, 2.5)) //设置图像的大小</span></span><br><span class="line">    plt.plot(x_vals.detach().numpy(), y_vals.detach().numpy()) //描点绘制图像</span><br><span class="line">    plt.xlabel(<span class="string">'x'</span>)</span><br><span class="line">    plt.ylabel(name + <span class="string">'(x)'</span>) <span class="comment">#对横轴和纵轴进行命名</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">x = torch.arange(<span class="number">-8.0</span>, <span class="number">8.0</span>, <span class="number">0.1</span>, requires_grad=<span class="literal">True</span>) <span class="comment">#初始化x的范围，步长，梯度</span></span><br><span class="line">y = x.relu() <span class="comment">#对x进行非线性的变换</span></span><br><span class="line">xyplot(x, y, <span class="string">'relu'</span>) <span class="comment">#调用函数绘图，可以看到正数部分保持不变，负数部分清零了</span></span><br></pre></td></tr></table></figure>
<p><img src="https://cdn.kesci.com/rt_upload/070825B6A382411DA5BD7D14E67E8D54/q5hv7cdtna.png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">y.sum().backward() <span class="comment">#对y求梯度</span></span><br><span class="line">xyplot(x, x.grad, <span class="string">'grad of relu'</span>)</span><br></pre></td></tr></table></figure>
<p><img src="https://cdn.kesci.com/rt_upload/BFB05150DBD1474D9A9ECCB9CDF1DD39/q5hv7c3pxb.png"></p>
<h4 id="Sigmoid函数"><a href="#Sigmoid函数" class="headerlink" title="Sigmoid函数"></a>Sigmoid函数</h4><p>sigmoid函数可以将元素的值变换到0和1之间：</p>
<script type="math/tex; mode=display">
\text{sigmoid}(x) = \frac{1}{1 + \exp(-x)}.</script><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">y = x.sigmoid()</span><br><span class="line">xyplot(x, y, <span class="string">'sigmoid'</span>)</span><br></pre></td></tr></table></figure>
<p><img src="https://cdn.kesci.com/rt_upload/68FCB4E8142144458F13128B370D1C91/q5hv7dor11.png"></p>
<p>依据链式法则，sigmoid函数的导数</p>
<script type="math/tex; mode=display">
\text{sigmoid}'(x) = \text{sigmoid}(x)\left(1-\text{sigmoid}(x)\right).</script><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">x.grad.zero_() <span class="comment">#x的梯度清零（relu前面求过）</span></span><br><span class="line">y.sum().backward()  <span class="comment">#利用反向传播，求梯度</span></span><br><span class="line">xyplot(x, x.grad, <span class="string">'grad of sigmoid'</span>) <span class="comment">#sigmoid导数的图像</span></span><br></pre></td></tr></table></figure>
<p><img src="https://cdn.kesci.com/rt_upload/878C7B8823304F72860965E119A21412/q5hv7dpse9.png"></p>
<h4 id="tanh函数"><a href="#tanh函数" class="headerlink" title="tanh函数"></a>tanh函数</h4><p><u>tanh（双曲正切）函数可以将元素的值变换到-1和1之间：</u></p>
<script type="math/tex; mode=display">
\text{tanh}(x) = \frac{1 - \exp(-2x)}{1 + \exp(-2x)}.</script><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">y = x.tanh() <span class="comment">#调用双曲正切函数得到函数值y</span></span><br><span class="line">xyplot(x, y, <span class="string">'tanh'</span>) <span class="comment">#绘制双曲正切函数的图像</span></span><br></pre></td></tr></table></figure>
<p><img src="https://cdn.kesci.com/rt_upload/92D16076309F42169482834C0B6ABB24/q5hv7dfeso.png"></p>
<p>依据链式法则，tanh函数的导数（[0,1])</p>
<script type="math/tex; mode=display">
\text{tanh}'(x) = 1 - \text{tanh}^2(x).</script><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">x.grad.zero_()</span><br><span class="line">y.sum().backward()</span><br><span class="line">xyplot(x, x.grad, <span class="string">'grad of tanh'</span>)</span><br></pre></td></tr></table></figure>
<p><img src="https://cdn.kesci.com/rt_upload/CB16F4B33E664E14BCE8E52D8B37C47F/q5hv7ejc8y.png"></p>
<h3 id="关于激活函数的选择"><a href="#关于激活函数的选择" class="headerlink" title="关于激活函数的选择"></a>关于激活函数的选择</h3><ul>
<li><p>ReLU函数<u>只能在隐藏层中使用</u>。</p>
</li>
<li><p>用于分类器时，sigmoid函数及其组合通常效果更好。由于梯度消失问题，有时要避免使用sigmoid和tanh函数。  </p>
</li>
</ul>
<ul>
<li>在<u>神经网络层数较多</u>的时候，最好使用<u>ReLu函数</u></li>
</ul>
<p>在选择激活函数的时候可以先选用ReLu函数如果效果不理想可以尝试其他激活函数。</p>
<h3 id="多层感知机-1"><a href="#多层感知机-1" class="headerlink" title="多层感知机"></a>多层感知机</h3><p>多层感知机就是<u>含有至少一个隐藏层</u>的由全连接层组成的神经网络，且每个隐藏层的输出通过<u>激活函数</u>进行变换。</p>
<script type="math/tex; mode=display">
\begin{aligned} \boldsymbol{H} &= \phi(\boldsymbol{X} \boldsymbol{W}_h + \boldsymbol{b}_h),\\ \boldsymbol{O} &= \boldsymbol{H} \boldsymbol{W}_o + \boldsymbol{b}_o, \end{aligned}</script><p>其中$\phi$表示激活函数。</p>
<h2 id="多层感知机从零开始的实现"><a href="#多层感知机从零开始的实现" class="headerlink" title="多层感知机从零开始的实现"></a>多层感知机从零开始的实现</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line">sys.path.append(<span class="string">"/home/kesci/input"</span>)</span><br><span class="line"><span class="keyword">import</span> d2lzh1981 <span class="keyword">as</span> d2l</span><br><span class="line">print(torch.__version__)</span><br></pre></td></tr></table></figure>
<h3 id="获取训练集"><a href="#获取训练集" class="headerlink" title="获取训练集"></a>获取训练集</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">batch_size = <span class="number">256</span></span><br><span class="line">train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size,root=<span class="string">'/home/kesci/input/FashionMNIST2065'</span>)</span><br></pre></td></tr></table></figure>
<h3 id="定义模型参数"><a href="#定义模型参数" class="headerlink" title="定义模型参数"></a>定义模型参数</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">num_inputs, num_outputs, num_hiddens = <span class="number">784</span>, <span class="number">10</span>, <span class="number">256</span> <span class="comment">#定义模型参数 输入参数28x28的的图像，输出10种类型，隐藏层的输入个数</span></span><br><span class="line"><span class="comment">#初始化两种权重和偏差</span></span><br><span class="line">W1 = torch.tensor(np.random.normal(<span class="number">0</span>, <span class="number">0.01</span>, (num_inputs, num_hiddens)), dtype=torch.float)</span><br><span class="line">b1 = torch.zeros(num_hiddens, dtype=torch.float)</span><br><span class="line">W2 = torch.tensor(np.random.normal(<span class="number">0</span>, <span class="number">0.01</span>, (num_hiddens, num_outputs)), dtype=torch.float)</span><br><span class="line">b2 = torch.zeros(num_outputs, dtype=torch.float)</span><br><span class="line"></span><br><span class="line">params = [W1, b1, W2, b2]</span><br><span class="line"><span class="keyword">for</span> param <span class="keyword">in</span> params:</span><br><span class="line">    param.requires_grad_(requires_grad=<span class="literal">True</span>) <span class="comment">#对参数进行梯度附加</span></span><br></pre></td></tr></table></figure>
<h3 id="定义激活函数"><a href="#定义激活函数" class="headerlink" title="定义激活函数"></a>定义激活函数</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">relu</span><span class="params">(X)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> torch.max(input=X, other=torch.tensor(<span class="number">0.0</span>)) <span class="comment">#将X和0比较，X大于0，保留；否则X为0</span></span><br></pre></td></tr></table></figure>
<h3 id="定义网络"><a href="#定义网络" class="headerlink" title="定义网络"></a>定义网络</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">//两层网络，隐藏层和输出层</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">net</span><span class="params">(X)</span>:</span> <span class="comment">#输入特征X</span></span><br><span class="line">    X = X.view((<span class="number">-1</span>, num_inputs)) <span class="comment">#X变形</span></span><br><span class="line">    H = relu(torch.matmul(X, W1) + b1) <span class="comment">#将X输入隐藏层 X与权重进行矩阵乘法 ，再加上bias，将整个结果输入到relu，得到H</span></span><br><span class="line">    <span class="keyword">return</span> torch.matmul(H, W2) + b2 <span class="comment">#输出层</span></span><br></pre></td></tr></table></figure>
<h3 id="定义损失函数"><a href="#定义损失函数" class="headerlink" title="定义损失函数"></a>定义损失函数</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">loss = torch.nn.CrossEntropyLoss()  <span class="comment">#交叉熵损失函数，判定function的好坏</span></span><br></pre></td></tr></table></figure>
<h3 id="训练"><a href="#训练" class="headerlink" title="训练"></a>训练</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">num_epochs, lr = <span class="number">5</span>, <span class="number">100.0</span> <span class="comment">#训练周期5 </span></span><br><span class="line"><span class="comment"># def train_ch3(net, train_iter, test_iter, loss, num_epochs, batch_size,</span></span><br><span class="line"><span class="comment">#               params=None, lr=None, optimizer=None):</span></span><br><span class="line"><span class="comment">#     for epoch in range(num_epochs):</span></span><br><span class="line"><span class="comment">#         train_l_sum, train_acc_sum, n = 0.0, 0.0, 0</span></span><br><span class="line"><span class="comment">#         for X, y in train_iter:</span></span><br><span class="line"><span class="comment">#             y_hat = net(X)</span></span><br><span class="line"><span class="comment">#             l = loss(y_hat, y).sum()</span></span><br><span class="line"><span class="comment">#             </span></span><br><span class="line"><span class="comment">#             # 梯度清零</span></span><br><span class="line"><span class="comment">#             if optimizer is not None:</span></span><br><span class="line"><span class="comment">#                 optimizer.zero_grad()</span></span><br><span class="line"><span class="comment">#             elif params is not None and params[0].grad is not None:</span></span><br><span class="line"><span class="comment">#                 for param in params:</span></span><br><span class="line"><span class="comment">#                     param.grad.data.zero_()</span></span><br><span class="line"><span class="comment">#            </span></span><br><span class="line"><span class="comment">#             l.backward()</span></span><br><span class="line"><span class="comment">#             if optimizer is None:</span></span><br><span class="line"><span class="comment">#                 d2l.sgd(params, lr, batch_size)</span></span><br><span class="line"><span class="comment">#             else:</span></span><br><span class="line"><span class="comment">#                 optimizer.step()  # “softmax回归的简洁实现”一节将用到</span></span><br><span class="line"><span class="comment">#             </span></span><br><span class="line"><span class="comment">#             </span></span><br><span class="line"><span class="comment">#             train_l_sum += l.item()</span></span><br><span class="line"><span class="comment">#             train_acc_sum += (y_hat.argmax(dim=1) == y).sum().item()</span></span><br><span class="line"><span class="comment">#             n += y.shape[0]</span></span><br><span class="line"><span class="comment">#         test_acc = evaluate_accuracy(test_iter, net)</span></span><br><span class="line"><span class="comment">#         print('epoch %d, loss %.4f, train acc %.3f, test acc %.3f'</span></span><br><span class="line"><span class="comment">#               % (epoch + 1, train_l_sum / n, train_acc_sum / n, test_acc))</span></span><br><span class="line"></span><br><span class="line">d2l.train_ch3(net, train_iter, test_iter, loss, num_epochs, batch_size, params, lr)</span><br></pre></td></tr></table></figure>
<pre><code>epoch 1, loss 0.0030, train acc 0.712, test acc 0.806
epoch 2, loss 0.0019, train acc 0.821, test acc 0.806
epoch 3, loss 0.0017, train acc 0.847, test acc 0.825
epoch 4, loss 0.0015, train acc 0.856, test acc 0.834
epoch 5, loss 0.0015, train acc 0.863, test acc 0.847
</code></pre><h2 id="多层感知机pytorch实现"><a href="#多层感知机pytorch实现" class="headerlink" title="多层感知机pytorch实现"></a>多层感知机pytorch实现</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">from</span> torch.nn <span class="keyword">import</span> init</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line">sys.path.append(<span class="string">"/home/kesci/input"</span>)</span><br><span class="line"><span class="keyword">import</span> d2lzh1981 <span class="keyword">as</span> d2l</span><br><span class="line"></span><br><span class="line">print(torch.__version__)</span><br></pre></td></tr></table></figure>
<pre><code>1.3.0
</code></pre><h3 id="初始化模型和各个参数"><a href="#初始化模型和各个参数" class="headerlink" title="初始化模型和各个参数"></a>初始化模型和各个参数</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">num_inputs, num_outputs, num_hiddens = <span class="number">784</span>, <span class="number">10</span>, <span class="number">256</span></span><br><span class="line">    </span><br><span class="line">net = nn.Sequential( </span><br><span class="line">        d2l.FlattenLayer(), <span class="comment">#数据变换，28x28 -&gt;784</span></span><br><span class="line">        nn.Linear(num_inputs, num_hiddens), <span class="comment">#隐藏层</span></span><br><span class="line">        nn.ReLU(), <span class="comment">#transformation</span></span><br><span class="line">        nn.Linear(num_hiddens, num_outputs), <span class="comment">#输出层</span></span><br><span class="line">        )</span><br><span class="line">    </span><br><span class="line"><span class="keyword">for</span> params <span class="keyword">in</span> net.parameters():</span><br><span class="line">    init.normal_(params, mean=<span class="number">0</span>, std=<span class="number">0.01</span>) <span class="comment">#参数正态初始化</span></span><br></pre></td></tr></table></figure>
<h3 id="训练-1"><a href="#训练-1" class="headerlink" title="训练"></a>训练</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">batch_size = <span class="number">256</span></span><br><span class="line">train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size,root=<span class="string">'/home/kesci/input/FashionMNIST2065'</span>)</span><br><span class="line">loss = torch.nn.CrossEntropyLoss()</span><br><span class="line"></span><br><span class="line">optimizer = torch.optim.SGD(net.parameters(), lr=<span class="number">0.5</span>) <span class="comment">#优化器</span></span><br><span class="line"></span><br><span class="line">num_epochs = <span class="number">5</span></span><br><span class="line">d2l.train_ch3(net, train_iter, test_iter, loss, num_epochs, batch_size, <span class="literal">None</span>, <span class="literal">None</span>, optimizer)</span><br></pre></td></tr></table></figure>
<pre><code>epoch 1, loss 0.0031, train acc 0.701, test acc 0.774
epoch 2, loss 0.0019, train acc 0.821, test acc 0.806
epoch 3, loss 0.0017, train acc 0.841, test acc 0.805
epoch 4, loss 0.0015, train acc 0.855, test acc 0.834
epoch 5, loss 0.0014, train acc 0.866, test acc 0.840
</code></pre><h1 id="文本预处理"><a href="#文本预处理" class="headerlink" title="文本预处理"></a>文本预处理</h1><p>文本是一类序列数据，一篇文章可以看作是字符或单词的序列，本节将介绍文本数据的常见预处理步骤，预处理通常包括四个步骤：</p>
<ol>
<li>读入文本</li>
<li>分词</li>
<li>建立字典，将每个词映射到一个唯一的索引（index）</li>
<li>将文本从<u>词的序列转换为索引的序列</u>，方便输入模型</li>
</ol>
<h2 id="读入文本"><a href="#读入文本" class="headerlink" title="读入文本"></a>读入文本</h2><p>H. G. Well的<a href="http://www.gutenberg.org/ebooks/35" target="_blank" rel="noopener">Time Machine</a></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> collections</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">read_time_machine</span><span class="params">()</span>:</span></span><br><span class="line">  <span class="comment">#创建文件对象f，f可迭代，</span></span><br><span class="line">    <span class="keyword">with</span> open(<span class="string">'/home/kesci/input/timemachine7163/timemachine.txt'</span>, <span class="string">'r'</span>) <span class="keyword">as</span> f:</span><br><span class="line">        lines = [re.sub(<span class="string">'[^a-z]+'</span>, <span class="string">' '</span>, line.strip().lower()) <span class="keyword">for</span> line <span class="keyword">in</span> f] <span class="comment">#按行处理，strip()去掉空白字符，lower()转化为小写，re.sub()正则表达式的替换函数，将字符串可以匹配为[^a-z]的子串替换为空格</span></span><br><span class="line">        <span class="comment">#[^a-z]+由非小写字符构成的非空字符串</span></span><br><span class="line">    <span class="keyword">return</span> lines <span class="comment">#list</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">lines = read_time_machine()</span><br><span class="line">print(<span class="string">'# sentences %d'</span> % len(lines))</span><br></pre></td></tr></table></figure>
<h2 id="分词"><a href="#分词" class="headerlink" title="分词"></a>分词</h2><p>我们对每个句子进行分词，也就是将一个句子划分成若干个词（token），转换为一个词的序列。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">tokenize</span><span class="params">(sentences, token=<span class="string">'word'</span>)</span>:</span> <span class="comment">#sentences为列表，token标志，分词的级别</span></span><br><span class="line">    <span class="string">"""Split sentences into word or char tokens"""</span></span><br><span class="line">    <span class="keyword">if</span> token == <span class="string">'word'</span>: <span class="comment">#单词级别的分词</span></span><br><span class="line">        <span class="keyword">return</span> [sentence.split(<span class="string">' '</span>) <span class="keyword">for</span> sentence <span class="keyword">in</span> sentences]</span><br><span class="line">    <span class="keyword">elif</span> token == <span class="string">'char'</span>: </span><br><span class="line">        <span class="keyword">return</span> [list(sentence) <span class="keyword">for</span> sentence <span class="keyword">in</span> sentences] </span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        print(<span class="string">'ERROR: unkown token type '</span>+token)</span><br><span class="line"><span class="comment">#返回的二维列表</span></span><br><span class="line">tokens = tokenize(lines)</span><br><span class="line">tokens[<span class="number">0</span>:<span class="number">2</span>]</span><br></pre></td></tr></table></figure>
<h2 id="建立字典"><a href="#建立字典" class="headerlink" title="建立字典"></a>建立字典</h2><p>为了方便模型处理，我们需要将字符串转换为数字。因此我们需要先构建一个字典（vocabulary），<u>将每个词映射到一个唯一的索引编号。</u></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Vocab</span><span class="params">(object)</span>:</span> <span class="comment">#查询索引返回对应的词</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, tokens, min_freq=<span class="number">0</span>, use_special_tokens=False)</span>:</span> <span class="comment">#tokens 前面token的返回结果，min_freq=0预值，小于的忽略</span></span><br><span class="line">        counter = count_corpus(tokens): <span class="comment">#&lt;key, value&gt; &lt;词，词频&gt;统计词频，可以根据词频去重</span></span><br><span class="line">        self.token_freqs = list(counter.items())<span class="comment">#将统计词频的二元组构造成一个列表</span></span><br><span class="line">        self.idx_to_token = [] <span class="comment">#列表，记录字典需要维护的token</span></span><br><span class="line">        <span class="keyword">if</span> use_special_tokens:</span><br><span class="line">            <span class="comment"># padding补长句子, begin of sentence, end of sentence, unknown</span></span><br><span class="line">            self.pad, self.bos, self.eos, self.unk = (<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>)</span><br><span class="line">            self.idx_to_token += [<span class="string">'&lt;pad&gt;'</span>, <span class="string">'&lt;bos&gt;'</span>, <span class="string">'&lt;eos&gt;'</span>, <span class="string">'&lt;unk&gt;'</span>] </span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            self.unk = <span class="number">0</span></span><br><span class="line">            self.idx_to_token += [<span class="string">'&lt;'</span>]</span><br><span class="line">        self.idx_to_token += [token <span class="keyword">for</span> token, freq <span class="keyword">in</span> self.token_freqs</span><br><span class="line">                        <span class="keyword">if</span> freq &gt;= min_freq <span class="keyword">and</span> token <span class="keyword">not</span> <span class="keyword">in</span> self.idx_to_token]<span class="comment">#token添加到index【list】</span></span><br><span class="line">        self.token_to_idx = dict()</span><br><span class="line">        <span class="keyword">for</span> idx, token <span class="keyword">in</span> enumerate(self.idx_to_token): </span><br><span class="line">            self.token_to_idx[token] = idx <span class="comment">#将每个词和下标添加</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__len__</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> len(self.idx_to_token)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__getitem__</span><span class="params">(self, tokens)</span>:</span> <span class="comment">#词到索引</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> isinstance(tokens, (list, tuple)): </span><br><span class="line">            <span class="keyword">return</span> self.token_to_idx.get(tokens, self.unk)</span><br><span class="line">        <span class="keyword">return</span> [self.__getitem__(token) <span class="keyword">for</span> token <span class="keyword">in</span> tokens]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">to_tokens</span><span class="params">(self, indices)</span>:</span> <span class="comment">#索引到词</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> isinstance(indices, (list, tuple)):</span><br><span class="line">            <span class="keyword">return</span> self.idx_to_token[indices]</span><br><span class="line">        <span class="keyword">return</span> [self.idx_to_token[index] <span class="keyword">for</span> index <span class="keyword">in</span> indices]</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">count_corpus</span><span class="params">(sentences)</span>:</span></span><br><span class="line">    tokens = [tk <span class="keyword">for</span> st <span class="keyword">in</span> sentences <span class="keyword">for</span> tk <span class="keyword">in</span> st] <span class="comment">#二维转一维列表</span></span><br><span class="line">    <span class="keyword">return</span> collections.Counter(tokens)  <span class="comment"># 返回一个字典，记录每个词的出现次数</span></span><br></pre></td></tr></table></figure>
<p>我们看一个例子，这里我们尝试用Time Machine作为语料构建字典</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">vocab = Vocab(tokens)</span><br><span class="line">print(list(vocab.token_to_idx.items())[<span class="number">0</span>:<span class="number">10</span>])</span><br></pre></td></tr></table></figure>
<h2 id="将词转为索引"><a href="#将词转为索引" class="headerlink" title="将词转为索引"></a>将词转为索引</h2><p>使用字典，我们可以将原文本中的句子从单词序列转换为索引序列</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">8</span>, <span class="number">10</span>):</span><br><span class="line">    print(<span class="string">'words:'</span>, tokens[i])</span><br><span class="line">    print(<span class="string">'indices:'</span>, vocab[tokens[i]])</span><br></pre></td></tr></table></figure>
<h2 id="用现有工具进行分词"><a href="#用现有工具进行分词" class="headerlink" title="用现有工具进行分词"></a>用现有工具进行分词</h2><p>我们前面介绍的分词方式非常简单，它至少有以下几个缺点:</p>
<ol>
<li>标点符号通常可以提供语义信息，但是我们的方法直接将其丢弃了</li>
<li>类似“shouldn’t”, “doesn’t”这样的词会被错误地处理</li>
<li>类似”Mr.”, “Dr.”这样的词会被错误地处理</li>
</ol>
<p>我们可以通过引入更复杂的规则来解决这些问题，但是事实上，有一些现有的工具可以很好地进行分词，我们在这里简单介绍其中的两个：<a href="https://spacy.io/" target="_blank" rel="noopener">spaCy</a>和<a href="https://www.nltk.org/" target="_blank" rel="noopener">NLTK</a>。</p>
<p>下面是一个简单的例子：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">text = <span class="string">"Mr. Chen doesn't agree with my suggestion."</span></span><br></pre></td></tr></table></figure>
<p>spaCy:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> spacy</span><br><span class="line">nlp = spacy.load(<span class="string">'en_core_web_sm'</span>) <span class="comment">#language</span></span><br><span class="line">doc = nlp(text)</span><br><span class="line">print([token.text <span class="keyword">for</span> token <span class="keyword">in</span> doc])</span><br></pre></td></tr></table></figure>
<p>NLTK:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> nltk.tokenize <span class="keyword">import</span> word_tokenize</span><br><span class="line"><span class="keyword">from</span> nltk <span class="keyword">import</span> data</span><br><span class="line">data.path.append(<span class="string">'/home/kesci/input/nltk_data3784/nltk_data'</span>)</span><br><span class="line">print(word_tokenize(text))</span><br></pre></td></tr></table></figure>
<h1 id="语言模型"><a href="#语言模型" class="headerlink" title="语言模型"></a>语言模型</h1><p>语言模型的目标就是<u>评估该序列是否合理</u>，即<u>计算该序列的概率</u>：</p>
<script type="math/tex; mode=display">
P(w_1, w_2, \ldots, w_T).</script><p>概率的大小判断合理程度</p>
<h2 id="语言模型-1"><a href="#语言模型-1" class="headerlink" title="语言模型"></a>语言模型</h2><p>假设序列$w_1$, w_2, \ldots, w_T$中的每个词是依次生成的，我们有</p>
<script type="math/tex; mode=display">
\begin{align*}P(w_1, w_2, \ldots, w_T)&= \prod_{t=1}^T P(w_t \mid w_1, \ldots, w_{t-1})\\&= P(w_1)P(w_2 \mid w_1) \cdots P(w_T \mid w_1w_2\cdots w_{T-1})\end{align*}</script><p>例如，一段含有4个词的文本序列的概率</p>
<script type="math/tex; mode=display">
P(w_1, w_2, w_3, w_4) =  P(w_1) P(w_2 \mid w_1) P(w_3 \mid w_1, w_2) P(w_4 \mid w_1, w_2, w_3).</script><p>语言模型的参数就是词的概率以及给定前几个词情况下的条件概率。</p>
<p>设训练数据集为一个大型文本语料库，词的概率可以通过该词在训练数据集中的相对词频来计算，例如，$w_1$的概率可以计算为：</p>
<script type="math/tex; mode=display">
\hat P(w_1) = \frac{n(w_1)}{n}</script><p>其中$n(w_1)$为语料库中以$w_1$作为第一个词的文本的数量，$n$为语料库中文本的总数量。</p>
<p>类似的，给定$w_1$情况下，$w_2$的条件概率可以计算为：</p>
<script type="math/tex; mode=display">
\hat P(w_2 \mid w_1) = \frac{n(w_1, w_2)}{n(w_1)}</script><p>其中$n(w_1, w_2)$为语料库中以$w_1$作为第一个词，$w_2$作为第二个词的文本的数量。</p>
<h2 id="n元语法"><a href="#n元语法" class="headerlink" title="n元语法"></a>n元语法</h2><p>序列长度增加，计算和存储多个词共同出现的概率的复杂度会呈指数级增加。$n$元语法通过马尔可夫假设简化模型，马尔科夫假设是指一个词的出现只与前面$n$个词相关，即$n$阶马尔可夫链（Markov chain of order $n$），如果$n=1$，那么有$P(w_3 \mid w_1, w_2) = P(w_3 \mid w_2)$。基于$n-1$阶马尔可夫链，我们可以将语言模型改写为</p>
<script type="math/tex; mode=display">
P(w_1, w_2, \ldots, w_T) = \prod_{t=1}^T P(w_t \mid w_{t-(n-1)}, \ldots, w_{t-1}) .</script><p>以上也叫$n$元语法（$n$-grams），它是基于$n - 1$阶马尔可夫链的概率语言模型。例如，当$n=2$时，含有4个词的文本序列的概率就可以改写为：</p>
<script type="math/tex; mode=display">
\begin{align*}
P(w_1, w_2, w_3, w_4)
&= P(w_1) P(w_2 \mid w_1) P(w_3 \mid w_1, w_2) P(w_4 \mid w_1, w_2, w_3)\\
&= P(w_1) P(w_2 \mid w_1) P(w_3 \mid w_2) P(w_4 \mid w_3)
\end{align*}</script><p>当$n$分别为1、2和3时，我们将其分别称作一元语法（unigram）、二元语法（bigram）和三元语法（trigram）。例如，长度为4的序列$w_1, w_2, w_3, w_4$在<u>一元语法、二元语法和三元语法</u>中的概率分别为</p>
<script type="math/tex; mode=display">
\begin{aligned}
P(w_1, w_2, w_3, w_4) &=  P(w_1) P(w_2) P(w_3) P(w_4) ,\\
P(w_1, w_2, w_3, w_4) &=  P(w_1) P(w_2 \mid w_1) P(w_3 \mid w_2) P(w_4 \mid w_3) ,\\
P(w_1, w_2, w_3, w_4) &=  P(w_1) P(w_2 \mid w_1) P(w_3 \mid w_1, w_2) P(w_4 \mid w_2, w_3) .
\end{aligned}</script><p>当$n$较小时，$n$元语法往往并不准确。例如，在一元语法中，由三个词组成的句子“你走先”和“你先走”的概率是一样的。然而，当$n$较大时，$n$元语法需要计算并存储大量的词频和多词相邻频率。</p>
<p>思考：$n$元语法可能有哪些缺陷？</p>
<ol>
<li>参数空间过大  v+v*n。。。</li>
<li>数据稀疏 （单词可能很少或者不会再语料库中出现）</li>
</ol>
<h1 id="语言模型数据集"><a href="#语言模型数据集" class="headerlink" title="语言模型数据集"></a>语言模型数据集</h1><h2 id="读取数据集"><a href="#读取数据集" class="headerlink" title="读取数据集"></a>读取数据集</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> open(<span class="string">'/home/kesci/input/jaychou_lyrics4703/jaychou_lyrics.txt'</span>) <span class="keyword">as</span> f:</span><br><span class="line">    corpus_chars = f.read() </span><br><span class="line">print(len(corpus_chars))</span><br><span class="line">print(corpus_chars[: <span class="number">40</span>])<span class="comment">#输出前40个字符</span></span><br><span class="line">corpus_chars = corpus_chars.replace(<span class="string">'\n'</span>, <span class="string">' '</span>).replace(<span class="string">'\r'</span>, <span class="string">' '</span>) <span class="comment">#换行回车-》空格</span></span><br><span class="line">corpus_chars = corpus_chars[: <span class="number">10000</span>]<span class="comment">#只保留前1w个字符</span></span><br></pre></td></tr></table></figure>
<pre><code>63282
想要有直升机
想要和你飞到宇宙去
想要和你融化在一起
融化在宇宙里
我每天每天每
</code></pre><h2 id="建立字符索引"><a href="#建立字符索引" class="headerlink" title="建立字符索引"></a>建立字符索引</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">idx_to_char = list(set(corpus_chars)) <span class="comment"># 去重，得到索引到字符的映射，转换为列表</span></span><br><span class="line">char_to_idx = &#123;char: i <span class="keyword">for</span> i, char <span class="keyword">in</span> enumerate(idx_to_char)&#125; <span class="comment"># 字符到索引的映射 枚举每个字符和下标</span></span><br><span class="line">vocab_size = len(char_to_idx)</span><br><span class="line">print(vocab_size)</span><br><span class="line"></span><br><span class="line">corpus_indices = [char_to_idx[char] <span class="keyword">for</span> char <span class="keyword">in</span> corpus_chars]  <span class="comment"># 将每个字符转化为索引，得到一个索引的序列</span></span><br><span class="line">sample = corpus_indices[: <span class="number">20</span>]  <span class="comment">#取出前20个字符</span></span><br><span class="line">print(<span class="string">'chars:'</span>, <span class="string">''</span>.join([idx_to_char[idx] <span class="keyword">for</span> idx <span class="keyword">in</span> sample])) <span class="comment">#拼接字符</span></span><br><span class="line">print(<span class="string">'indices:'</span>, sample)</span><br></pre></td></tr></table></figure>
<pre><code>1027 
chars: 想要有直升机 想要和你飞到宇宙去 想要和
indices: [238, 161, 522, 830, 265, 156, 778, 238, 161, 36, 799, 107, 694, 904, 290, 244, 778, 238, 161, 36]
</code></pre><p>定义函数<code>load_data_jay_lyrics</code>，在后续章节中直接调用。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">load_data_jay_lyrics</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="keyword">with</span> open(<span class="string">'/home/kesci/input/jaychou_lyrics4703/jaychou_lyrics.txt'</span>) <span class="keyword">as</span> f:</span><br><span class="line">        corpus_chars = f.read()</span><br><span class="line">    corpus_chars = corpus_chars.replace(<span class="string">'\n'</span>, <span class="string">' '</span>).replace(<span class="string">'\r'</span>, <span class="string">' '</span>)</span><br><span class="line">    corpus_chars = corpus_chars[<span class="number">0</span>:<span class="number">10000</span>]</span><br><span class="line">    idx_to_char = list(set(corpus_chars))</span><br><span class="line">    char_to_idx = dict([(char, i) <span class="keyword">for</span> i, char <span class="keyword">in</span> enumerate(idx_to_char)])</span><br><span class="line">    vocab_size = len(char_to_idx)</span><br><span class="line">    corpus_indices = [char_to_idx[char] <span class="keyword">for</span> char <span class="keyword">in</span> corpus_chars]</span><br><span class="line">    <span class="keyword">return</span> corpus_indices, char_to_idx, idx_to_char, vocab_size <span class="comment">#返回映射 字典大小</span></span><br></pre></td></tr></table></figure>
<h2 id="时序数据的采样"><a href="#时序数据的采样" class="headerlink" title="时序数据的采样"></a>时序数据的采样</h2><p>在训练中我们需要每次随机读取小批量样本和标签。与之前章节的实验数据不同的是，时序数据的一个样本通常包含连续的字符。假设时间步数为5，样本序列为5个字符，即“想”“要”“有”“直”“升”。该样本的标签序列为这些字符分别在训练集中的下一个字符，即“要”“有”“直”“升”“机”，即$X$=“想要有直升”，$Y$=“要有直升机”。</p>
<p>现在我们考虑序列“<u>想要有直升机，想要和你飞到宇宙去</u>”（训练数据），如果时间步数为5，有以下可能的样本和标签：</p>
<ul>
<li>$X$：“想要有直升”，$Y$：“要有直升机”</li>
<li>$X$：“要有直升机”，$Y$：“有直升机，”</li>
<li>$X$：“有直升机，”，$Y$：“直升机，想”</li>
<li>…</li>
<li>$X$：“要和你飞到”，$Y$：“和你飞到宇”</li>
<li>$X$：“和你飞到宇”，$Y$：“你飞到宇宙”</li>
<li>$X$：“你飞到宇宙”，$Y$：“飞到宇宙去”</li>
</ul>
<p>可以看到，如果<u>序列的长度为$T$</u>，<u>时间步数为$n$</u>，那么一共有<u>$T-n$个</u>合法的样本，但是这些样本有<u>大量的重合</u>，我们通常采用更加高效的采样方式。我们有两种方式对时序数据进行采样，分别是<u>随机采样和相邻采样</u>。</p>
<h3 id="随机采样"><a href="#随机采样" class="headerlink" title="随机采样"></a>随机采样</h3><p>批量大小<code>batch_size</code>是每个小批量的样本数，<code>num_steps</code>是每个样本所包含的时间步数。</p>
<ul>
<li>按时间步数给序列分组，忽略不足时间步数的分组</li>
<li>每个分组作为批量</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="comment">#corpus_indices 序列，batch_size批量大小，num_steps时间步数，device控制批量的返回设备</span></span><br><span class="line"><span class="comment">#1.计算序列可以划分成多少个分组</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">data_iter_random</span><span class="params">(corpus_indices, batch_size, num_steps, device=None)</span>:</span></span><br><span class="line">    <span class="comment"># 减1是因为对于长度为n的序列，X最多只有包含其中的前n - 1个字符</span></span><br><span class="line">    num_examples = (len(corpus_indices) - <span class="number">1</span>) // num_steps  <span class="comment"># 下取整，得到不重叠情况下的样本个数</span></span><br><span class="line">    example_indices = [i * num_steps <span class="keyword">for</span> i <span class="keyword">in</span> range(num_examples)]  <span class="comment"># 记录下标，每个样本的第一个字符在corpus_indices序列中的下标</span></span><br><span class="line">    random.shuffle(example_indices) <span class="comment">#随机采样</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_data</span><span class="params">(i)</span>:</span></span><br><span class="line">        <span class="comment"># 返回从i开始的长为num_steps时间步数的序列</span></span><br><span class="line">        <span class="keyword">return</span> corpus_indices[i: i + num_steps]</span><br><span class="line">    <span class="keyword">if</span> device <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">        device = torch.device(<span class="string">'cuda'</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">'cpu'</span>)</span><br><span class="line">    <span class="comment">#构造随机样本</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>, num_examples, batch_size):</span><br><span class="line">        <span class="comment"># 每次选出batch_size个随机样本</span></span><br><span class="line">        batch_indices = example_indices[i: i + batch_size]  <span class="comment"># 当前batch的各个样本的首字符的下标</span></span><br><span class="line">        X = [_data(j) <span class="keyword">for</span> j <span class="keyword">in</span> batch_indices]<span class="comment">#利用下标j取出对应的样本</span></span><br><span class="line">        Y = [_data(j + <span class="number">1</span>) <span class="keyword">for</span> j <span class="keyword">in</span> batch_indices]<span class="comment">#取出对应的标签</span></span><br><span class="line">        <span class="keyword">yield</span> torch.tensor(X, device=device), torch.tensor(Y, device=device)</span><br></pre></td></tr></table></figure>
<p>测试一下这个函数，我们输入从0到29的连续整数作为一个人工序列，设批量大小和时间步数分别为2和6，打印随机采样每次读取的小批量样本的输入<code>X</code>和标签<code>Y</code>。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">my_seq = list(range(<span class="number">30</span>))</span><br><span class="line"><span class="keyword">for</span> X, Y <span class="keyword">in</span> data_iter_random(my_seq, batch_size=<span class="number">2</span>, num_steps=<span class="number">6</span>):</span><br><span class="line">    print(<span class="string">'X: '</span>, X, <span class="string">'\nY:'</span>, Y, <span class="string">'\n'</span>)</span><br></pre></td></tr></table></figure>
<pre><code>X:  tensor([[ 0,  1,  2,  3,  4,  5],
        [ 6,  7,  8,  9, 10, 11]]) 
Y: tensor([[ 1,  2,  3,  4,  5,  6],
        [ 7,  8,  9, 10, 11, 12]]) 

X:  tensor([[18, 19, 20, 21, 22, 23],
        [12, 13, 14, 15, 16, 17]]) 
Y: tensor([[19, 20, 21, 22, 23, 24],
        [13, 14, 15, 16, 17, 18]]) 
</code></pre><h3 id="相邻采样"><a href="#相邻采样" class="headerlink" title="相邻采样"></a>相邻采样</h3><ul>
<li><p>在训练数据上是连续的</p>
</li>
<li><p>根据批量大小等分序列 </p>
</li>
<li><p>在每个分组里根据步长等分，每一个分组里取得每个batch的一部分</p>
<p><img src="/cinzyh.github.io/.io//备注 2020年2月14日.jpg" alt></p>
</li>
</ul>
<p>在相邻采样中，相邻的两个随机小批量在原始序列上的位置相毗邻、</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">data_iter_consecutive</span><span class="params">(corpus_indices, batch_size, num_steps, device=None)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> device <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">        device = torch.device(<span class="string">'cuda'</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">'cpu'</span>)</span><br><span class="line">    corpus_len = len(corpus_indices) // batch_size * batch_size  <span class="comment"># 保留下来的序列的长度</span></span><br><span class="line">    corpus_indices = corpus_indices[: corpus_len]  <span class="comment"># 仅保留前corpus_len个字符</span></span><br><span class="line">    indices = torch.tensor(corpus_indices, device=device)</span><br><span class="line">    indices = indices.view(batch_size, <span class="number">-1</span>)  <span class="comment"># resize成(batch_size, )，二维</span></span><br><span class="line">    batch_num = (indices.shape[<span class="number">1</span>] - <span class="number">1</span>) // num_steps <span class="comment">#-1 ，样本不包含最后一个字符</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(batch_num):</span><br><span class="line">        i = i * num_steps</span><br><span class="line">        X = indices[:, i: i + num_steps]</span><br><span class="line">        Y = indices[:, i + <span class="number">1</span>: i + num_steps + <span class="number">1</span>]</span><br><span class="line">        <span class="keyword">yield</span> X, Y</span><br></pre></td></tr></table></figure>
<p>同样的设置下，打印相邻采样每次读取的小批量样本的输入<code>X</code>和标签<code>Y</code>。相邻的两个随机小批量在原始序列上的位置相毗邻。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> X, Y <span class="keyword">in</span> data_iter_consecutive(my_seq, batch_size=<span class="number">2</span>, num_steps=<span class="number">6</span>):</span><br><span class="line">    print(<span class="string">'X: '</span>, X, <span class="string">'\nY:'</span>, Y, <span class="string">'\n'</span>)</span><br></pre></td></tr></table></figure>
<pre><code>X:  tensor([[ 0,  1,  2,  3,  4,  5],
        [15, 16, 17, 18, 19, 20]]) 
Y: tensor([[ 1,  2,  3,  4,  5,  6],
        [16, 17, 18, 19, 20, 21]]) 

X:  tensor([[ 6,  7,  8,  9, 10, 11],
        [21, 22, 23, 24, 25, 26]]) 
Y: tensor([[ 7,  8,  9, 10, 11, 12],
        [22, 23, 24, 25, 26, 27]]) 
</code></pre><h1 id="循环神经网络"><a href="#循环神经网络" class="headerlink" title="循环神经网络"></a>循环神经网络</h1><ul>
<li><p>基于循环神经网络实现语言模型。</p>
</li>
<li><p>目的：基于当前的输入与过去的输入序列，预测序列的下一个字符。</p>
</li>
<li><p>循环神经网络引入一个隐藏变量$H$，用$H_{t}$表示$H$在时间步$t$的值。$H_{t}$的计算基于$X_{t}$和$H_{t-1}$，可以认为$H_{t}$记录了到当前字符为止的序列信息，利用$H_{t}$对序列的下一个字符进行预测。<br><img src="https://cdn.kesci.com/upload/image/q5jkm0v44i.png?imageView2/0/w/640/h/640" alt="Image Name"></p>
</li>
</ul>
<h2 id="循环神经网络的构造"><a href="#循环神经网络的构造" class="headerlink" title="循环神经网络的构造"></a>循环神经网络的构造</h2><p>假设$\boldsymbol{X}_t \in \mathbb{R}^{n \times d}$是时间步$t$的小批量输入，$\boldsymbol{H}_t  \in \mathbb{R}^{n \times h}$是该时间步的隐藏变量，则：</p>
<script type="math/tex; mode=display">
\boldsymbol{H}_t = \phi(\boldsymbol{X}_t \boldsymbol{W}_{xh} + \boldsymbol{H}_{t-1} \boldsymbol{W}_{hh}  + \boldsymbol{b}_h).</script><p>在时间步$t$，输出层的输出为：</p>
<script type="math/tex; mode=display">
\boldsymbol{O}_t = \boldsymbol{H}_t \boldsymbol{W}_{hq} + \boldsymbol{b}_q.</script><h3 id="one-hot向量"><a href="#one-hot向量" class="headerlink" title="one-hot向量"></a>one-hot向量</h3><p>将字符表示成向量</p>
<ul>
<li>长度等于字典大小</li>
<li>只有一个元素是1，其他元素为0的向量</li>
<li>对任意一个字符，one-hot向量，索引所在的位置为1，其他的位置为0</li>
</ul>
<h2 id><a href="#" class="headerlink" title=" "></a> </h2>
          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://cinzyh.github.io/cinzyh.github.io/2020/02/06/hexo%E5%AE%89%E8%A3%85%E6%95%99%E7%A8%8Bmac+coding+github/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="cinzyh">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/cinzyh.github.io/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="cinzyh_Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/cinzyh.github.io/2020/02/06/hexo%E5%AE%89%E8%A3%85%E6%95%99%E7%A8%8Bmac+coding+github/" itemprop="url">hexo入门教程：mac+hexo+github</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2020-02-06T16:45:46+08:00">
                2020-02-06
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/cinzyh.github.io/categories/%E6%95%99%E7%A8%8B/" itemprop="url" rel="index">
                    <span itemprop="name">教程</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="node-hexo的安装"><a href="#node-hexo的安装" class="headerlink" title="node+hexo的安装"></a>node+hexo的安装</h1><h2 id="安装Node-js"><a href="#安装Node-js" class="headerlink" title="安装Node.js"></a>安装Node.js</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"># 首先检查是否安装了git和node.js，终端输入一下命令，</span><br><span class="line">node -v #是否出现安装版本信息，出现说明已经安装了</span><br><span class="line">git --version #同上述情况</span><br><span class="line"># 如果没有安装，则进行安装,都可以通过直接下载安装测序进行安装，这里不演示，提供下载网址：</span><br><span class="line">[git]: https:&#x2F;&#x2F;sourceforge.net&#x2F;projects&#x2F;git-osx-installer&#x2F;</span><br><span class="line">[node.js]: https:&#x2F;&#x2F;nodejs.org&#x2F;en&#x2F;</span><br></pre></td></tr></table></figure>
<h2 id="安装Hexo"><a href="#安装Hexo" class="headerlink" title="安装Hexo"></a>安装Hexo</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">npm install -g hexo-cli</span><br></pre></td></tr></table></figure>
<p>这时候可能会报权限相关的错误，可以使用sudo安装。最好使用<a href="https://docs.npmjs.com/resolving-eacces-permissions-errors-when-installing-packages-globally" target="_blank" rel="noopener">官方的解决方案</a></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">mkdir blog #创建一个名为blog的文件目录，可自行命名</span><br><span class="line">cd blog #进入目录</span><br><span class="line">hexo init #初始化目录</span><br><span class="line">hexo s #开启本地服务</span><br></pre></td></tr></table></figure>
<p>如果出现了 <img src="/cinzyh.github.io/.io//wox/blog/source/_posts/hexo安装教程mac+coding+github/image-20200207141246689.jpg">就可以在本地访问了。</p>
<p><em>如果出现了 <strong>command not found</strong>的问题：</em></p>
<ul>
<li><p>可能是没有将hexo配置到环境变量中，如果你采用了官方的解决方案，可以看到hexo在npm-global这个目录里（如果采用的官方的解决方法） <img class="-20200207142653320.jpg"></p>
</li>
<li><p>将hexo 的路径添加到环境变量中</p>
</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">open ~&#x2F;.bash_profile  #打开配置文件</span><br></pre></td></tr></table></figure>
<p>在里面添加hexo的路径</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">export HEXO&#x3D;&quot;&#x2F;Users&#x2F;[你的用户名]&#x2F;.npm-global&#x2F;lib&#x2F;node_modules&#x2F;hexo-cli&quot;</span><br><span class="line">export PATH&#x3D;$PATH:$HEXO&#x2F;bin</span><br></pre></td></tr></table></figure>
<p>保存后，在终端里输入’ : $source ~/.bash_profile’使环境变量生效，可以输入’which hexo’可以查看hexo的路径。环境变量生效后输入hexo会显示<img src="/cinzyh.github.io/.io//wox/blog/source/_posts/hexo安装教程mac+coding+github/image-20200207143725276.jpg" style="zoom:80%;"></p>
<h1 id="部署到github-coding上"><a href="#部署到github-coding上" class="headerlink" title="部署到github+coding上"></a>部署到github+coding上</h1><p>在github上注册账号后Create a new repository，创建仓库的名字必须为<strong>username.github.io</strong> [username]就是你的用户名，比如我的是<strong>cinzyh.github.io</strong></p>
<h4 id="将博客关联到github"><a href="#将博客关联到github" class="headerlink" title="将博客关联到github"></a>将博客关联到github</h4><p>打开blog目录下的<em>_config.yml</em>文件，做出相应的修改</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"># Deployment</span><br><span class="line">## Docs: https:&#x2F;&#x2F;hexo.io&#x2F;docs&#x2F;deployment.html</span><br><span class="line">deploy:</span><br><span class="line">  type: git </span><br><span class="line">  repo: git@github.com:cinzyh&#x2F;cinzyh.github.io.git#填自己的，可以是ssh也可以是https</span><br><span class="line">  branch: master</span><br><span class="line">  name: cinzyh#填自己的</span><br><span class="line">  email: cinpukka@outlook.com#填自己的</span><br></pre></td></tr></table></figure>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://cinzyh.github.io/cinzyh.github.io/2020/02/06/hello-world/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="cinzyh">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/cinzyh.github.io/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="cinzyh_Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/cinzyh.github.io/2020/02/06/hello-world/" itemprop="url">Hello World</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2020-02-06T14:18:56+08:00">
                2020-02-06
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>Welcome to <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="noopener">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="noopener">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="noopener">GitHub</a>.</p>
<h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">"My New Post"</span></span><br></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="noopener">Writing</a></p>
<h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="noopener">Server</a></p>
<h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="noopener">Generating</a></p>
<h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/one-command-deployment.html" target="_blank" rel="noopener">Deployment</a></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
  </section>

  


          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      

      <section class="site-overview-wrap sidebar-panel sidebar-panel-active">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image"
                src="/cinzyh.github.io/images/avatar.gif"
                alt="cinzyh" />
            
              <p class="site-author-name" itemprop="name">cinzyh</p>
              <p class="site-description motion-element" itemprop="description"></p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/cinzyh.github.io/archives/%20%7C%7C%20archive">
              
                  <span class="site-state-item-count">3</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/cinzyh.github.io/categories/index.html">
                  <span class="site-state-item-count">1</span>
                  <span class="site-state-item-name">分类</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/cinzyh.github.io/tags/index.html">
                  <span class="site-state-item-count">2</span>
                  <span class="site-state-item-name">标签</span>
                </a>
              </div>
            

          </nav>

          

          

          
          

          
          

          

        </div>
      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">cinzyh</span>

  
</div>


  <div class="powered-by">由 <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a> 强力驱动</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">主题 &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Muse</a> v5.1.4</div>




        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/cinzyh.github.io/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/cinzyh.github.io/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/cinzyh.github.io/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/cinzyh.github.io/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/cinzyh.github.io/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/cinzyh.github.io/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/cinzyh.github.io/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/cinzyh.github.io/js/src/motion.js?v=5.1.4"></script>



  
  

  

  


  <script type="text/javascript" src="/cinzyh.github.io/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  





  

  

  

  
  

  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdn.bootcss.com/mathjax/2.7.1/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
  


  

  

</body>
</html>
